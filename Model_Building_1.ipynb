{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISI SPRING 2019 RESEARCH PROJECT \n",
    "* By: Huy Nghiem\n",
    "* Assingment for the spam classifcation project for the USC MINDS research group.\n",
    "* TASK: Classify whether e-mails are spams or not and produce metrics for model performance. \n",
    "* In this module, we build a simple Logistic Regerssion model to classify spams and report on their requested performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "%load_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spambase.data\", header=None)\n",
    "feat = df.loc[:,:56].values #Must convert to np array for later use\n",
    "label = df.loc[:,57].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "Based from the explorations, we see that this dataset has high variance and \n",
    "some variables are highly correlated with each other. \n",
    "Perform max-scaling and standardization transformation on the data to combat this and for better use of machine learning techniques later.\n",
    "Afer scaling, each variable should have mean 0 and unit STD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STDscale(train,test): \n",
    "    '''Perform standard scaling on dataset. \n",
    "    Note: we must perform scaling on the training set \n",
    "    and then use these statitics to scale the test set\n",
    "    '''\n",
    "    scaler = StandardScaler().fit(train)\n",
    "    df_train_scaled = scaler.transform(train)\n",
    "    df_test_scaled = scaler.transform(test)\n",
    "    return df_train_scaled, df_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESION Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Logistic Regression (LR) model for this claffication task.\n",
    "LR is a good starting point since we have 50+ features with ~5000 observations, \n",
    "heuristically good enough for a linear technique.\n",
    "\n",
    "We will peform k-fold Cross-validation and apply the model on the k-1 folds and test on the held out form. We shuffle the data before splitting to prevent over-concentration in 1 fold and not in another.\n",
    "\n",
    "We perform standard scaling on the training data and apply the statistics on the held out data. The LR model is fit on each training set and performance metrics is reported for each fold.\n",
    "We also use [lbfgs] solver under the hoood for fast convergence on small data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on performane metrics\n",
    "* False Positive: non-spams misclassified as spam (1)\n",
    "* False Negative: spam but misclassified as non-spam (0)\n",
    "* FPR = $\\frac{FP}{FP+TN}$ \n",
    "\n",
    "* FNR = $\\frac{FN}{FN+TP}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResult(test_label, test_pred, num_train):\n",
    "    '''Tally counts for true positive, False Positive,\n",
    "        False Netgative, True Negative, Along with\n",
    "        Accuracy Rate and Error Rate \n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(test_label, test_pred).ravel()\n",
    "    fpr = round(fp/(fp+tn),2)\n",
    "    fnr = round(fn/(fn+tp),2)\n",
    "    acc = (test_pred == test_label).astype(int).sum()/num_train*100\n",
    "    err = (test_pred != test_label).astype(int).sum()/num_train*100\n",
    "    return tn, fp, fn, tp, fpr, fnr, acc, err "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify hyperparameters\n",
    "num_k = 5\n",
    "col_names = [\"TN\",\"FP\",\"FN\",\"TP\",\"FPR\",\"FNR\",\"ACC%\",\"ERR%\"]\n",
    "result = np.zeros((1,len(col_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the LR model using 10-fold Cross Validation technique.\n",
    "We employed L-2 norm regularization to combat overfitting. \n",
    "Note that for each fold, we fit (calculate statistics) on training set and \n",
    "scale using these statistics on both train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING at FOLD 1 with 3680 training obs., 921 testing obs. \n",
      "Accuracy: 93.7 %\n",
      "Error: 6.3 %\n",
      "TESTING at FOLD 2 with 3681 training obs., 920 testing obs. \n",
      "Accuracy: 90.11 %\n",
      "Error: 9.89 %\n",
      "TESTING at FOLD 3 with 3681 training obs., 920 testing obs. \n",
      "Accuracy: 94.35 %\n",
      "Error: 5.65 %\n",
      "TESTING at FOLD 4 with 3681 training obs., 920 testing obs. \n",
      "Accuracy: 90.54 %\n",
      "Error: 9.46 %\n",
      "TESTING at FOLD 5 with 3681 training obs., 920 testing obs. \n",
      "Accuracy: 93.04 %\n",
      "Error: 6.96 %\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "kf = KFold(n_splits=num_k, shuffle=True, random_state=123)\n",
    "kf.get_n_splits(feat)\n",
    "i = 1\n",
    "with warnings.catch_warnings(): \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    for train_idx, test_idx in kf.split(feat):\n",
    "        N, T  = train_idx.size, test_idx.size\n",
    "        print(\"TESTING at FOLD %s with %s training obs., %s testing obs. \" % (i, N, T)  )\n",
    "        x_train, x_test = feat[train_idx], feat[test_idx]\n",
    "        y_train, y_test = label[train_idx], label[test_idx]\n",
    "        #Perform scaling on train_set\n",
    "        x_train, x_test = STDscale(x_train,x_test)\n",
    "        #Fit the model\n",
    "        LR = LogisticRegression(penalty=\"l2\", solver='lbfgs')\n",
    "        LR.fit(x_train,y_train)\n",
    "        y_pred = LR.predict(x_test)\n",
    "        tn,fp,fn,tp,fpr,fnr,acc,err = getResult(y_test, y_pred, T)\n",
    "        result = np.vstack((result, [tn,fp,fn,tp,fpr,fnr,acc,err]))\n",
    "        print(\"Accuracy: %s %%\" % round(acc,2))\n",
    "        print(\"Error: %s %%\" % round(err,2))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[1:]\n",
    "avg_result = np.sum(result,axis=0)/result.shape[0]\n",
    "avg_result[:4] = 0\n",
    "result = np.vstack((result,avg_result))\n",
    "final_result = pd.DataFrame(result,columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>ACC%</th>\n",
       "      <th>ERR%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>535.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.080</td>\n",
       "      <td>93.702497</td>\n",
       "      <td>6.297503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>490.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.130</td>\n",
       "      <td>90.108696</td>\n",
       "      <td>9.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>558.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.100</td>\n",
       "      <td>94.347826</td>\n",
       "      <td>5.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>511.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.150</td>\n",
       "      <td>90.543478</td>\n",
       "      <td>9.456522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>553.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.110</td>\n",
       "      <td>93.043478</td>\n",
       "      <td>6.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.114</td>\n",
       "      <td>92.349195</td>\n",
       "      <td>7.650805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TN    FP    FN     TP    FPR    FNR       ACC%      ERR%\n",
       "0  535.0  28.0  30.0  328.0  0.050  0.080  93.702497  6.297503\n",
       "1  490.0  40.0  51.0  339.0  0.080  0.130  90.108696  9.891304\n",
       "2  558.0  17.0  35.0  310.0  0.030  0.100  94.347826  5.652174\n",
       "3  511.0  30.0  57.0  322.0  0.060  0.150  90.543478  9.456522\n",
       "4  553.0  26.0  38.0  303.0  0.040  0.110  93.043478  6.956522\n",
       "5    0.0   0.0   0.0    0.0  0.052  0.114  92.349195  7.650805"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "In part 1, using a simple 5-fold cross validation, we see observe an average accuracy rate of roughly 85 percent. This approach is a bit naive due to the following reasons:\n",
    "* Lack of a testing set: A separate test set set aside to provide an objective basis to compare our model.\n",
    "* In the Exploration phase, we noticed a high degree of correlations between variables. Logistic Regression is notorious for its susceptibility to this phenomena. Peforming PCA on this set may be a remedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION Part 2\n",
    "In this part, we enhance the former Logistic Regression Model by applying Principal Component Analysis (PCA) when fitting the model. PCA is a general dimensionality-reduction techniques to get represent a sample to a number of principle components that stil capture the majority of variance.\n",
    "PCA reduces redundancy from correlated features and \"explain\" the data in fewer axes/components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def PCAtransform(train,test,var_ratio=0.95):\n",
    "    '''\n",
    "    Perform a PCA transformation on the train and test set\n",
    "    with a ratio of at least 95% variance. \n",
    "    Note: PCA will select the MINIMUM number of principal components \n",
    "    to ratain 95% of the variance. \n",
    "    '''\n",
    "    vr = var_ratio\n",
    "    pca = PCA(var_ratio)\n",
    "    pca.fit(train)\n",
    "    train_pca = pca.transform(train)\n",
    "    test_pca = pca.transform(test)\n",
    "    return train_pca, test_pca, pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This time, we increase the number of folds to 10, double that of the last round.\n",
    "num_k = 10\n",
    "result = np.zeros((1,len(col_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING at FOLD 1 with 4140 training obs., 461 testing obs. \n",
      "Accuracy: 93.93 %\n",
      "Error: 6.07 %\n",
      "TESTING at FOLD 2 with 4141 training obs., 460 testing obs. \n",
      "Accuracy: 94.13 %\n",
      "Error: 5.87 %\n",
      "TESTING at FOLD 3 with 4141 training obs., 460 testing obs. \n",
      "Accuracy: 91.09 %\n",
      "Error: 8.91 %\n",
      "TESTING at FOLD 4 with 4141 training obs., 460 testing obs. \n",
      "Accuracy: 90.65 %\n",
      "Error: 9.35 %\n",
      "TESTING at FOLD 5 with 4141 training obs., 460 testing obs. \n",
      "Accuracy: 94.78 %\n",
      "Error: 5.22 %\n",
      "TESTING at FOLD 6 with 4141 training obs., 460 testing obs. \n",
      "Accuracy: 93.7 %\n",
      "Error: 6.3 %\n",
      "TESTING at FOLD 7 with 4141 training obs., 460 testing obs. \n",
      "Accuracy: 90.87 %\n",
      "Error: 9.13 %\n",
      "TESTING at FOLD 8 with 4141 training obs., 460 testing obs. \n",
      "Accuracy: 90.65 %\n",
      "Error: 9.35 %\n",
      "TESTING at FOLD 9 with 4141 training obs., 460 testing obs. \n",
      "Accuracy: 93.04 %\n",
      "Error: 6.96 %\n",
      "TESTING at FOLD 10 with 4141 training obs., 460 testing obs. \n",
      "Accuracy: 92.83 %\n",
      "Error: 7.17 %\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "kf = KFold(n_splits=num_k,shuffle=True,random_state=123)\n",
    "kf.get_n_splits(feat)\n",
    "i = 1\n",
    "with warnings.catch_warnings(): \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    for train_idx, test_idx in kf.split(feat):\n",
    "        N, T  = train_idx.size, test_idx.size\n",
    "        print(\"TESTING at FOLD %s with %s training obs., %s testing obs. \" % (i, N, T)  )\n",
    "        x_train, x_test = feat[train_idx], feat[test_idx]\n",
    "        y_train, y_test = label[train_idx], label[test_idx]\n",
    "        #Perform scaling on train_set\n",
    "        x_train_scaled, x_test_scaled = STDscale(x_train,x_test)\n",
    "        x_train_pca, x_test_pca, var_ratio = PCAtransform(x_train_scaled,x_test_scaled)\n",
    "        #print(\"{}% of variance explained on the training set\".format(np.sum(var_ratio)))\n",
    "        #Fit the model\n",
    "        LR = LogisticRegression(penalty=\"l2\", solver='lbfgs')\n",
    "        LR.fit(x_train_pca,y_train)\n",
    "        y_pred = LR.predict(x_test_pca)\n",
    "        tn,fp,fn,tp,fpr,fnr,acc,err = getResult(y_test, y_pred, T)\n",
    "        result = np.vstack((result, [tn,fp,fn,tp,fpr,fnr,acc,err]))\n",
    "        print(\"Accuracy: %s %%\" % round(acc,2))\n",
    "        print(\"Error: %s %%\" % round(err,2))\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[1:]\n",
    "avg_result = np.sum(result,axis=0)/result.shape[0]\n",
    "avg_result[:4] = 0\n",
    "result = np.vstack((result,avg_result))\n",
    "final_result = pd.DataFrame(result,columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>ACC%</th>\n",
       "      <th>ERR%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.080</td>\n",
       "      <td>93.926247</td>\n",
       "      <td>6.073753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.080</td>\n",
       "      <td>94.130435</td>\n",
       "      <td>5.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.120</td>\n",
       "      <td>91.086957</td>\n",
       "      <td>8.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.150</td>\n",
       "      <td>90.652174</td>\n",
       "      <td>9.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>288.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.100</td>\n",
       "      <td>94.782609</td>\n",
       "      <td>5.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.110</td>\n",
       "      <td>93.695652</td>\n",
       "      <td>6.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>254.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.140</td>\n",
       "      <td>90.869565</td>\n",
       "      <td>9.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>257.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.150</td>\n",
       "      <td>90.652174</td>\n",
       "      <td>9.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>275.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.090</td>\n",
       "      <td>93.043478</td>\n",
       "      <td>6.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>277.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.130</td>\n",
       "      <td>92.826087</td>\n",
       "      <td>7.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.115</td>\n",
       "      <td>92.566538</td>\n",
       "      <td>7.433462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TN    FP    FN     TP    FPR    FNR       ACC%      ERR%\n",
       "0   265.0  13.0  15.0  168.0  0.050  0.080  93.926247  6.073753\n",
       "1   272.0  13.0  14.0  161.0  0.050  0.080  94.130435  5.869565\n",
       "2   242.0  17.0  24.0  177.0  0.070  0.120  91.086957  8.913043\n",
       "3   256.0  15.0  28.0  161.0  0.060  0.150  90.652174  9.347826\n",
       "4   288.0   8.0  16.0  148.0  0.030  0.100  94.782609  5.217391\n",
       "5   270.0   9.0  20.0  161.0  0.030  0.110  93.695652  6.304348\n",
       "6   254.0  16.0  26.0  164.0  0.060  0.140  90.869565  9.130435\n",
       "7   257.0  14.0  29.0  160.0  0.050  0.150  90.652174  9.347826\n",
       "8   275.0  17.0  15.0  153.0  0.060  0.090  93.043478  6.956522\n",
       "9   277.0  10.0  23.0  150.0  0.030  0.130  92.826087  7.173913\n",
       "10    0.0   0.0   0.0    0.0  0.049  0.115  92.566538  7.433462"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBSERVATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy and Error Rate are comparable between part 1 and 2.\n",
    "A quick look over the respective results for the K-Fold tables reveal \n",
    "signifiance performance metrics for each fold. \n",
    "\n",
    "An average Accuracy of roughly 92% on testing set appears decent.\n",
    "The slight increase in average Accuracy makes sense as a for each fold, the model benefits from learning more data.\n",
    "\n",
    "The result reveals that our LR model produces higher __False Negatives Rate__ than __False Positives Rate__. But in terms of raw counts, we might want to reduce FN more, as we do not want to miss imporant emails.\n",
    "\n",
    "For futher improvement, we can try other classfication models, such as SVM \n",
    "and Random Forest, which deal with the relatively high dimensionality \n",
    "differently. These are implemented in the module Model Building 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__END OF MODULE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
